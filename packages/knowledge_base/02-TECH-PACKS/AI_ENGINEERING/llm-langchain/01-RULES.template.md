# üìè Tech Governance Rules: LangChain

> **Fecha:** 30 de Enero de 2026
> **Estado:** ‚úÖ MANDATORY RULES
> **Alcance:** Todo c√≥digo Python que use LangChain en SoftArchitect

Reglas estrictas e inapelables para el desarrollo de IA con LangChain.

---

## üìñ Tabla de Contenidos

1. [La Regla de Oro: LCEL Mandatorio](#la-regla-de-oro-lcel-mandatorio)
2. [Gesti√≥n de Prompts](#gesti√≥n-de-prompts)
3. [Salidas Estructuradas](#salidas-estructuradas)
4. [Convenciones de Naming](#convenciones-de-naming)
5. [Validaci√≥n Autom√°tica](#validaci√≥n-autom√°tica)
6. [Anti-Patterns](#anti-patterns)

---

## La Regla de Oro: LCEL Mandatorio

### Regla 1: The Pipe Rule (`|`)

**Obligatorio:** TODO nuevo desarrollo debe usar **LCEL (LangChain Expression Language)** con el operador pipe.

**Sintaxis Permitida:**
```python
# ‚úÖ GOOD: LCEL Pipe
chain = prompt | model | parser
result = chain.invoke({"input": value})
async for chunk in chain.astream({"input": value}):
    print(chunk)
```

**Sintaxis Prohibida:**
```python
# ‚ùå BAD: Legacy LLMChain (Deprecated)
chain = LLMChain(llm=model, prompt=prompt)

# ‚ùå BAD: SimpleSequentialChain
chain = SimpleSequentialChain(chains=[chain1, chain2])

# ‚ùå BAD: ConversationChain (Deprecated)
chain = ConversationChain(llm=model, memory=memory)
```

### Rationale

1. **LCEL es m√°s legible:** `a | b | c` vs `LLMChain(llm=b, prompt=a)`
2. **LCEL es m√°s performante:** Streaming autom√°tico, sin overhead
3. **LCEL tiene mejor type safety:** Type hints correctos en el resultado
4. **LCEL est√° en mantenimiento activo:** Las clases legacy est√°n deprecadas desde v0.0.220

### Validaci√≥n en CI/CD

```bash
# Pre-commit hook busca estos strings prohibidos:
grep -r "LLMChain\|SimpleSequentialChain\|ConversationChain" src/
# Si encuentra algo ‚Üí REJECT commit
```

---

## Gesti√≥n de Prompts

### Regla 2: Templates Separados de C√≥digo

**Prohibido:** Hardcodear strings gigantes en el c√≥digo Python.

```python
# ‚ùå BAD
prompt_string = """
You are an expert in {domain}.
Answer the question: {question}
Provide a detailed response...
"""  # ‚Üê ¬°40 l√≠neas m√°s de templates!

model = ChatOllama(model="llama3")
chain = prompt_string | model  # Type error: str no es compatible
```

**Obligatorio:** Usar `ChatPromptTemplate` o `SystemMessagePromptTemplate`.

```python
# ‚úÖ GOOD: Templates estructurados
from langchain_core.prompts import ChatPromptTemplate, SystemMessagePromptTemplate

system_template = """You are an expert in {domain}.
Provide detailed, accurate responses."""

user_template = "Answer this question: {question}"

prompt = ChatPromptTemplate.from_messages([
    SystemMessagePromptTemplate.from_template(system_template),
    ("user", user_template)
])

# Ahora es type-safe
chain = prompt | model | parser
```

### D√≥nde Residem los Prompts

Ubicaci√≥n obligatoria:
```
src/
‚îú‚îÄ‚îÄ core/
‚îÇ   ‚îî‚îÄ‚îÄ prompts/
‚îÇ       ‚îú‚îÄ‚îÄ rag_prompts.py         # Prompts para RAG
‚îÇ       ‚îú‚îÄ‚îÄ agent_prompts.py       # Prompts para Agentes
‚îÇ       ‚îî‚îÄ‚îÄ summarization_prompts.py
```

Nunca en:
- ‚ùå Directamente en funciones
- ‚ùå En variables de entorno (salvo API keys)
- ‚ùå En constantes sin documentaci√≥n

### Ejemplo de Estructura

```python
# src/core/prompts/rag_prompts.py

from langchain_core.prompts import ChatPromptTemplate

RAG_SYSTEM_PROMPT = """You are a helpful assistant answering questions based on provided context.
Use ONLY the context provided. If the answer is not in the context, say "No information available."
"""

CONTEXT_TEMPLATE = """Context documents:
{context}"""

QUESTION_TEMPLATE = "Question: {question}"

rag_prompt = ChatPromptTemplate.from_messages([
    ("system", RAG_SYSTEM_PROMPT),
    ("user", CONTEXT_TEMPLATE + "\n\n" + QUESTION_TEMPLATE)
])
```

---

## Salidas Estructuradas

### Regla 3: Validaci√≥n Pydantic Obligatoria

**Prohibido:** Confiar en que el LLM devuelva JSON v√°lido por suerte.

```python
# ‚ùå BAD: JSON sin validaci√≥n
response = model.invoke(prompt)
json_str = response.content
parsed = json.loads(json_str)  # ¬øQu√© si no es v√°lido JSON?
```

**Obligatorio:** Usar `PydanticOutputParser` o `.with_structured_output()`.

```python
# ‚úÖ GOOD: Schema validado con Pydantic
from langchain_core.pydantic_v1 import BaseModel, Field
from langchain_core.output_parsers import PydanticOutputParser

class InvoiceData(BaseModel):
    """Estructura de una factura extra√≠da."""
    invoice_number: str = Field(description="N√∫mero de factura √∫nico")
    total_amount: float = Field(description="Monto total en USD")
    due_date: str = Field(description="Fecha de vencimiento (YYYY-MM-DD)")
    vendor_name: str = Field(description="Nombre del proveedor")

parser = PydanticOutputParser(pydantic_object=InvoiceData)

prompt = ChatPromptTemplate.from_template("""
Extract invoice data from this text:
{text}

{format_instructions}
""")

chain = prompt | model | parser

# Resultado es una instancia de InvoiceData, NO un string
invoice: InvoiceData = chain.invoke({
    "text": invoice_text,
    "format_instructions": parser.get_format_instructions()
})

print(invoice.total_amount)  # Type-safe ‚úÖ
```

### Alternativa: Function Calling (Si modelo lo soporta)

```python
# ‚úÖ GOOD: Usar .with_structured_output() para GPT-4/Claude
class SearchQuery(BaseModel):
    query: str
    filters: dict

structured_llm = model.with_structured_output(SearchQuery)
chain = prompt | structured_llm

result: SearchQuery = chain.invoke({...})
```

---

## Convenciones de Naming

### Regla 4: Naming Consistente

| Concepto | Convenci√≥n | Ejemplo |
|:---|:---|:---|
| **Cadenas LCEL** | Suffix `_chain` | `rag_chain`, `summarization_chain`, `agent_chain` |
| **Runnables Gen√©ricos** | Suffix `_runnable` | `parallel_runnable`, `conditional_runnable` |
| **Herramientas (Tools)** | Verbo + Objeto | `search_documents`, `calculate_tax`, `get_user_profile` |
| **Prompts** | Suffix `_prompt` | `system_prompt`, `retrieval_prompt` |
| **Parsers** | Suffix `_parser` | `json_parser`, `invoice_parser` |
| **Retrievers** | Suffix `_retriever` | `semantic_retriever`, `hybrid_retriever` |

```python
# ‚úÖ GOOD: Naming correcto
from langchain.tools import tool

# Chains
rag_chain = retriever | prompt | model | parser

# Runnables
parallel_runnable = RunnableParallel({
    "docs": retriever,
    "question": RunnablePassthrough()
})

# Tools
@tool
def search_documents(query: str) -> str:
    """Search knowledge base by query."""
    return retriever.invoke(query)

# Prompts
system_prompt = ChatPromptTemplate.from_template("You are helpful...")

# Parsers
json_parser = PydanticOutputParser(pydantic_object=MySchema)
```

---

## Validaci√≥n Autom√°tica

### Regla 5: Pre-commit Hooks

Archivo: `.pre-commit-config.yaml`

```yaml
- repo: local
  hooks:
    - id: langchain-lcel-check
      name: LangChain LCEL Validation
      entry: python -m scripts.validate_langchain
      language: system
      types: [python]
      stages: [commit]
```

Validaciones:
1. ‚ùå Rechazar `LLMChain`, `SimpleSequentialChain`, `ConversationChain`
2. ‚ùå Rechazar `hardcoded` prompts largos en `.py` (>50 caracteres sin `ChatPromptTemplate`)
3. ‚ùå Rechazar `json.loads()` sin try/except o validaci√≥n Pydantic
4. ‚úÖ Aceptar `|` (pipe) en cadenas
5. ‚úÖ Aceptar `.with_structured_output()` o `PydanticOutputParser`

---

## Anti-Patterns

### ‚ùå PROHIBIDO 1: Mezclar Legacy + LCEL

```python
# ‚ùå BAD: No mezcles paradigmas
from langchain.chains import LLMChain
from langchain_core.output_parsers import StrOutputParser

# Una usando legacy:
old_chain = LLMChain(llm=model, prompt=prompt)

# Otra usando LCEL:
new_chain = prompt | model | StrOutputParser()

# Ahora tienes inconsistencia de tipos/comportamiento
```

### ‚ùå PROHIBIDO 2: Ignorar Errores de Parsing

```python
# ‚ùå BAD: No capturar excepciones
invoice_data = parser.invoke(llm_output)

# Cuando la salida es inv√°lida ‚Üí crash sin contexto
```

**DEBE SER:**
```python
# ‚úÖ GOOD: Validaci√≥n con fallback
try:
    invoice_data = parser.invoke(llm_output)
except OutputParserException as e:
    logger.error(f"Parse error: {e}. Raw output: {llm_output}")
    invoice_data = InvoiceData.construct(
        invoice_number="UNKNOWN",
        total_amount=0.0,
        due_date="1970-01-01",
        vendor_name="UNKNOWN"
    )
```

### ‚ùå PROHIBIDO 3: Blocking Calls en Async Context

```python
# ‚ùå BAD: Mezclar sync/async
async def process_documents(docs):
    result = chain.invoke({"docs": docs})  # ‚Üê Blocking!
```

**DEBE SER:**
```python
# ‚úÖ GOOD: Usar async
async def process_documents(docs):
    result = await chain.ainvoke({"docs": docs})
```

### ‚ùå PROHIBIDO 4: No Loguear Prompts Enviados

```python
# ‚ùå BAD: Debugging imposible
chain = prompt | model | parser
result = chain.invoke({"input": data})

# ¬øQu√© prompt exacto se envi√≥ al LLM?
```

**DEBE SER:**
```python
# ‚úÖ GOOD: Loguear para debugging
import logging

logger = logging.getLogger(__name__)

formatted_prompt = prompt.format_messages(**{"input": data})
logger.debug(f"Sending prompt: {formatted_prompt}")

result = chain.invoke({"input": data})
logger.info(f"Chain result: {result}")
```

---

## Checklist Pre-Deploy

```bash
# ‚úÖ 1. LCEL Validation
[ ] Todas las cadenas usan pipe |
[ ] NO hay LLMChain, SimpleSequentialChain, ConversationChain
[ ] Prompts est√°n en src/core/prompts/

# ‚úÖ 2. Estructuras
[ ] Outputs validados con Pydantic
[ ] Todos los Fields tienen description
[ ] Parsing errors tienen fallback

# ‚úÖ 3. Naming
[ ] Cadenas tienen suffix _chain
[ ] Tools tienen verbo + objeto
[ ] Prompts tienen suffix _prompt

# ‚úÖ 4. Testing
[ ] Unit tests para cada chain
[ ] Mock LLM responses
[ ] Edge cases (empty input, timeout, error)

# ‚úÖ 5. Observabilidad
[ ] Prompts loguean en DEBUG
[ ] Results loguean en INFO
[ ] Errores loguean con contexto
[ ] LangSmith integrado (si prod)
```

---

**Validaci√≥n:** RAG rechazar√° PRs que violen estas reglas.

**Fecha:** 30 de Enero de 2026
**Status:** ‚úÖ ENFORCED
**Responsable:** ArchitectZero AI Agent
