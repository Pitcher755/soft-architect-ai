# ü™£ AWS S3 Storage Patterns

> **Servicio:** Simple Storage Service (S3)
> **Durabilidad:** 99.999999999% (11 nueves)
> **Disponibilidad:** 99.99%
> **Filosof√≠a:** "Tiering autom√°tico para ahorrar 90% en storage"
> **Estado:** ‚úÖ Establecido
> **Fecha:** 30/01/2026

---

## üìñ Tabla de Contenidos

1. [Conceptos Fundamentales](#conceptos-fundamentales)
2. [Storage Classes](#storage-classes)
3. [Lifecycle Policies](#lifecycle-policies)
4. [Security Best Practices](#security-best-practices)
5. [Cost Optimization](#cost-optimization)
6. [Advanced Patterns](#advanced-patterns)

---

## Conceptos Fundamentales

### Estructura de S3

```
S3 (Global service)
‚îú‚îÄ‚îÄ Bucket (Regi√≥n espec√≠fica)
‚îÇ   ‚îú‚îÄ‚îÄ Object (archivo + metadata)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Key (path: /folder/document.pdf)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Content-Type
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Tags
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Metadata (custom)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Version ID (si versionado)
```

### Naming Rules

```python
# ‚úÖ V√ÅLIDO
- my-bucket-2026
- bucket.example.com
- 123-bucket

# ‚ùå INV√ÅLIDO
- My-Bucket (may√∫sculas)
- bucket_ (underscore)
- -bucket (guion al inicio)
- bucket.example (conflicto con DNS)
```

### Acceso a Objetos

```
S3 es simple: Todo es HTTP.

Directa (NO RECOMENDADO en producci√≥n):
  https://my-bucket.s3.us-east-1.amazonaws.com/photo.jpg
  (Inseguro, expone el bucket directamente)

Via CloudFront (CDN - RECOMENDADO):
  https://d123abc.cloudfront.net/photo.jpg
  (Cachea, comprime, distribuye globalmente)

Via Presigned URL (Cliente √∫nico):
  https://my-bucket.s3.us-east-1.amazonaws.com/doc.pdf?X-Amz-Signature=...
  (Temporal, con permisos limitados)
```

---

## Storage Classes

### Cuando Cambiar de Tier

```
Tabla de Decisi√≥n:

Acceso FRECUENTE (diario)        ‚Üí S3 Standard ($0.023/GB/mes)
Acceso OCASIONAL (mensual)       ‚Üí S3 Standard-IA ($0.0125/GB/mes)
Acceso RARO (trimestral)         ‚Üí S3 Glacier Instant ($0.004/GB/mes)
Acceso MUY RARO (anual)          ‚Üí S3 Glacier Flexible ($0.0036/GB/mes)
Archivo LEGAL/COMPLIANCE (a√±os)  ‚Üí S3 Glacier Deep Archive ($0.00099/GB/mes)
```

### 1. S3 Standard (Hot)

```yaml
StorageClass: STANDARD

# Caracter√≠sticas
- Acceso inmediato
- Replicado en ‚â•3 AZs autom√°ticamente
- Throughput: Ilimitado
- Costo: M√°s alto, pero sin retrieval fees

# Caso de Uso
- Aplicaci√≥n web activa
- Logs diarios
- Assets din√°micos (im√°genes de perfil de usuarios activos)
```

### 2. S3 Standard-IA (Infrequent Access)

```yaml
StorageClass: STANDARD_IA

# Caracter√≠sticas
- Almacenamiento 40% m√°s barato que Standard
- PERO: Retrieval fee = $0.01 por GB descargado
- M√≠nimo de 30 d√≠as de almacenamiento
- M√≠nimo de 128KB por objeto (archivos peque√±os no aplican)

# Caso de Uso
- Backups mensuales
- Logs de auditor√≠a (descarga rara)
- Documentos archivados (acceso ocasional)

# C√°lculo de ROI
Si un objeto est√° almacenado 90 d√≠as y se descarga 1 vez:
  Costo Standard (90 d√≠as):    $0.023 √ó 3 meses √ó GB = $0.069
  Costo IA (90 d√≠as + retrieval): ($0.0125 √ó 3 + $0.01) √ó GB = $0.0475
  Ahorro: ~30%
```

### 3. S3 Glacier Instant Retrieval

```yaml
StorageClass: GLACIER_IR

# Caracter√≠sticas
- Almacenamiento 80% m√°s barato
- Retrieval tarda: milisegundos (instant)
- M√≠nimo: 30 d√≠as
- M√≠nimo: 128KB

# Caso de Uso
- Respaldos trimestrales
- Archivos que necesitan acceso urgente pero raro
- Datos de sensores hist√≥ricos
```

### 4. S3 Glacier Flexible Retrieval

```yaml
StorageClass: GLACIER

# Caracter√≠sticas
- Almacenamiento 95% m√°s barato ($0.0036/GB/mes)
- Retrieval tard√≠o:
  * Standard: 3-5 horas
  * Bulk: 5-12 horas (m√°s barato)
  * Expedited: 1-5 min ($0.03 por GB)
- M√≠nimo: 90 d√≠as

# Caso de Uso
- Archivo anual (auditor√≠a, compliance)
- Backup de backup (√∫ltima l√≠nea de defensa)
- Datos cient√≠ficos hist√≥ricos
```

### 5. S3 Glacier Deep Archive

```yaml
StorageClass: DEEP_ARCHIVE

# Caracter√≠sticas
- Almacenamiento 99% m√°s barato ($0.00099/GB/mes)
- Retrieval tard√≠o:
  * Standard: 12 horas
  * Bulk: 48 horas
- M√≠nimo: 180 d√≠as
- Mejor durabilidad (m√°s copias)

# Caso de Uso
- Archivo legal (7+ a√±os)
- Backup de cumplimiento normativo (HIPAA, PCI)
- Raramente accedido pero cr√≠tico si se necesita

# Ejemplo Real
1TB de datos archivo anual:
  Standard:        $23 √ó 12 = $276/a√±o
  Deep Archive:    $1 √ó 12 = $12/a√±o
  Ahorro:          95%
```

---

## Lifecycle Policies

### Automatizar Transiciones

```yaml
# Configurar movimiento autom√°tico de objetos
# (No tienes que hacerlo manualmente)

LifecycleConfiguration:
  Rules:
    - Id: auto-archive-cold-data
      Status: Enabled

      # Aplicar a objetos con este prefijo
      Prefix: logs/
      Filter:
        Tags:
          Environment: production

      # Transici√≥n autom√°tica
      Transitions:
        - Days: 30
          StorageClass: STANDARD_IA

        - Days: 90
          StorageClass: GLACIER

        - Days: 180
          StorageClass: DEEP_ARCHIVE

      # Expiraci√≥n (borrar)
      Expiration:
        Days: 365  # Borrar despu√©s de 1 a√±o

      # Para versiones no-actuales (si versioning est√° ON)
      NoncurrentVersionTransitions:
        - NoncurrentDays: 30
          StorageClass: STANDARD_IA

      NoncurrentVersionExpiration:
        NoncurrentDays: 90
```

### Ejemplo Real: Sistema de Logs

```yaml
# Simular base de datos de logs sin base de datos

# Estructura:
# s3://logs-bucket/2026-01-30/app/api.log
# s3://logs-bucket/2026-01-29/app/api.log
# s3://logs-bucket/2026-01-15/app/api.log
# ...

LifecycleConfiguration:
  Rules:
    - Id: logs-tiering
      Status: Enabled
      Filter:
        Prefix: 'app/'

      Transitions:
        # Hoy: Standard (hot)
        # 7 d√≠as: Acceso frecuente (debuggear)

        - Days: 7
          StorageClass: STANDARD_IA
        # Despu√©s de 7 d√≠as: Acceso raro (business intelligence)

        - Days: 30
          StorageClass: GLACIER
        # Despu√©s de 30 d√≠as: Archivo (compliance)

        - Days: 90
          StorageClass: DEEP_ARCHIVE
        # Despu√©s de 90 d√≠as: Guardar para siempre

      Expiration:
        Days: 1825  # 5 a√±os de retenci√≥n legal
```

---

## Security Best Practices

### 1. Block Public Access (OBLIGATORIO)

```yaml
# Nivel Bucket
BucketPublicAccessBlockConfiguration:
  BlockPublicAcls: true
  BlockPublicPolicy: true
  IgnorePublicAcls: true
  RestrictPublicBuckets: true

# Nivel Cuenta (aplicar a TODOS los buckets autom√°ticamente)
AccountPublicAccessBlockConfiguration:
  BlockPublicAcls: true
  BlockPublicPolicy: true
  IgnorePublicAcls: true
  RestrictPublicBuckets: true
```

**¬øPor qu√©?**
```
Si un bucket est√° p√∫blico, cualquiera puede:
- Listar todos los objetos
- Descargarlos
- Subir malware
- Generar facturas enormes de egreso

Regla de Oro: S3 NUNCA debe estar p√∫blico directamente.
Alternativa: CloudFront (CDN) con Bucket Policy restringida.
```

### 2. Encryption (Encriptaci√≥n)

#### Server-Side Encryption (SSE)

```yaml
# Opci√≥n 1: SSE-S3 (AWS gestiona las claves)
BucketEncryption:
  Rules:
    - ApplyServerSideEncryptionByDefault:
        SSEAlgorithm: AES256  # ‚Üê Default, gratis

# Opci√≥n 2: SSE-KMS (Control con AWS KMS)
BucketEncryption:
  Rules:
    - ApplyServerSideEncryptionByDefault:
        SSEAlgorithm: aws:kms
        KMSMasterKeyID: arn:aws:kms:us-east-1:ACCOUNT:key/...
      BucketKeyEnabled: true  # Reduce costos KMS
```

#### Client-Side Encryption (Cliente encripta antes de enviar)

```python
# Python: Usar S3 client-side encryption
import boto3
from cryptography.fernet import Fernet

# Generar clave
key = Fernet.generate_key()

s3 = boto3.client('s3')

# Encriptar localmente
cipher = Fernet(key)
encrypted_data = cipher.encrypt(b'Datos sensibles')

# Subir encriptado
s3.put_object(
    Bucket='my-bucket',
    Key='sensitive/file.enc',
    Body=encrypted_data,
    Metadata={'encryption': 'client-side-fernet'}
)
```

### 3. Versioning (Protecci√≥n contra borrados)

```yaml
VersioningConfiguration:
  Status: Enabled

# Beneficios
# - Recuperaci√≥n ante borrados accidentales
# - Auditor√≠a (qui√©n cambi√≥ qu√© y cu√°ndo)
# - Protecci√≥n contra ransomware (versiones hist√≥ricas intactas)

# Combinado con Lifecycle:
NoncurrentVersionExpiration:
  NoncurrentDays: 90
# (Mantener √∫ltimas 90 d√≠as de versiones antiguas)
```

### 4. Logging (Auditor√≠a)

```yaml
# Registrar TODOS los accesos a un bucket
LoggingConfiguration:
  DestinationBucketName: logs-bucket
  LogFilePrefix: s3-access-logs/

# Cada acceso genera un objeto:
# s3://logs-bucket/s3-access-logs/2026-01-30-12-34-56-ABC123...

# Estructura del log
# Requester, Bucket, Key, RequestDateTime, Status, ErrorCode, BytesSent, ObjectSize, ...
```

### 5. Pol√≠ticas de Acceso (IAM + Bucket Policy)

```json
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Sid": "DenyUnencryptedObjectUploads",
      "Effect": "Deny",
      "Principal": "*",
      "Action": "s3:PutObject",
      "Resource": "arn:aws:s3:::my-bucket/*",
      "Condition": {
        "StringNotEquals": {
          "s3:x-amz-server-side-encryption": "aws:kms"
        }
      }
    },
    {
      "Sid": "AllowCloudFrontOnly",
      "Effect": "Allow",
      "Principal": {
        "AWS": "arn:aws:iam::cloudfront:user/CloudFront Principal User ID"
      },
      "Action": "s3:GetObject",
      "Resource": "arn:aws:s3:::my-bucket/*"
    }
  ]
}
```

---

## Cost Optimization

### Estrategias Reales

#### 1. Intelligent-Tiering

```yaml
# AWS lo hace autom√°ticamente por ti
StorageClass: INTELLIGENT_TIERING

# Monitorea acceso autom√°ticamente
# - No acceso 30 d√≠as ‚Üí STANDARD_IA
# - No acceso 90 d√≠as ‚Üí GLACIER
# - Acceso nuevamente ‚Üí Vuelve a STANDARD

# Costo: $0.0125/GB/mes (un poco m√°s que STANDARD)
# Valor: Zero management, optimizaci√≥n autom√°tica
```

#### 2. Eliminar Versiones Obsoletas

```python
# Script para limpiar versiones viejas
import boto3

s3 = boto3.client('s3')

paginator = s3.get_paginator('list_object_versions')

for page in paginator.paginate(Bucket='my-bucket'):
    for version in page.get('Versions', []):
        if version['IsLatest'] == False:
            # Borrar versi√≥n no-actual
            s3.delete_object(
                Bucket='my-bucket',
                Key=version['Key'],
                VersionId=version['VersionId']
            )

    for marker in page.get('DeleteMarkers', []):
        s3.delete_object(
            Bucket='my-bucket',
            Key=marker['Key'],
            VersionId=marker['VersionId']
        )
```

#### 3. Multipart Upload para Archivos Grandes

```python
# Subir archivo de 5GB en paralelo
import boto3
from concurrent.futures import ThreadPoolExecutor

s3 = boto3.client('s3')

# Iniciar upload de m√∫ltiples partes
response = s3.create_multipart_upload(
    Bucket='my-bucket',
    Key='large-file.zip'
)
upload_id = response['UploadId']

# Subir partes en paralelo (mucho m√°s r√°pido)
parts = []

def upload_part(part_number, data):
    response = s3.upload_part(
        Bucket='my-bucket',
        Key='large-file.zip',
        PartNumber=part_number,
        UploadId=upload_id,
        Body=data
    )
    return {
        'ETag': response['ETag'],
        'PartNumber': part_number
    }

with ThreadPoolExecutor(max_workers=8) as executor:
    futures = [
        executor.submit(upload_part, i, chunk)
        for i, chunk in enumerate(chunks, 1)
    ]
    parts = [f.result() for f in futures]

# Completar upload
s3.complete_multipart_upload(
    Bucket='my-bucket',
    Key='large-file.zip',
    UploadId=upload_id,
    MultipartUpload={'Parts': parts}
)
```

---

## Advanced Patterns

### 1. Presigned URLs (Acceso Temporal)

```python
import boto3
from datetime import timedelta

s3 = boto3.client('s3')

# Generar URL temporal (v√°lida 15 minutos)
url = s3.generate_presigned_url(
    'get_object',
    Params={
        'Bucket': 'my-bucket',
        'Key': 'documents/contract.pdf'
    },
    ExpiresIn=900  # 15 minutos
)

# Resultado:
# https://my-bucket.s3.us-east-1.amazonaws.com/documents/contract.pdf?X-Amz-Signature=...&X-Amz-Expires=900

# Cliente puede descargar sin credenciales
# Autom√°ticamente expira despu√©s de 900s
```

### 2. Cross-Region Replication (CRR)

```yaml
# Replicar autom√°ticamente a otra regi√≥n
# (para DR, latencia baja, conformidad)

ReplicationConfiguration:
  Role: arn:aws:iam::ACCOUNT:role/s3-replication
  Rules:
    - Id: replicate-all
      Status: Enabled
      Priority: 1
      Filter:
        Prefix: ''  # Replicar todo
      Destination:
        Bucket: arn:aws:s3:::my-bucket-replica-us-west-2
        ReplicationTime:
          Status: Enabled
          Time:
            Minutes: 15  # Replicar dentro de 15 min
        Metrics:
          Status: Enabled
```

### 3. S3 Event Notifications (Trigger Lambda)

```yaml
# Cuando subes un archivo ‚Üí Ejecutar Lambda autom√°ticamente

NotificationConfiguration:
  LambdaFunctionConfigurations:
    - Event: s3:ObjectCreated:*
      Filter:
        Key:
          FilterRules:
            - Name: prefix
              Value: uploads/
            - Name: suffix
              Value: .jpg
      LambdaFunctionArn: arn:aws:lambda:us-east-1:ACCOUNT:function:resize-image

# Uso real:
# Usuario sube image.jpg ‚Üí S3 trigger ‚Üí Lambda resize-image
# Lambda redimensiona, comprime, guarda thumbnail
# Todo autom√°tico en segundos
```

---

## Resumen: S3 Mastery

‚úÖ **Reglas Inmutables:**
- Nunca p√∫blico (BLOCK PUBLIC ACCESS activado)
- Versioning + Lifecycle = Backup + Ahorro
- CloudFront para servir assets (no S3 directo)
- Presigned URLs para acceso temporal
- CRR para DR

‚úÖ **Checklist de Seguridad:**
- [ ] Block Public Access: true
- [ ] Encryption: SSE-KMS
- [ ] Versioning: Enabled
- [ ] Logging: Configured
- [ ] Lifecycle: Policies en place
- [ ] MFA Delete: true (para buckets cr√≠ticos)

‚úÖ **Ahorros T√≠picos:**
- Lifecycle + Tiering: 80% reducci√≥n en storage
- Intelligent-Tiering: Zero management
- Presigned URLs: Mejor que ampliar IAM

AWS S3 es el coraz√≥n del data lake. ü™£‚ú®
