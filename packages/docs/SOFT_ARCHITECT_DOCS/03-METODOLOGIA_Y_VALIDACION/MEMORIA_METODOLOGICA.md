#  Memoria Metodol贸gica: El Origen y las Herramientas

## 1. Origen de la Idea
Este proyecto nace como respuesta a una necesidad detectada durante el propio cursado del M谩ster en Desarrollo con IA: **la necesidad de operacionalizar el conocimiento**.

En lugar de dejar la teor铆a de los m贸dulos (Ingenier铆a, Arquitectura, Seguridad) en PDFs est谩ticos, la idea es **crear un sistema que contenga ese conocimiento y ayude a aplicarlo activamente**. Es un proyecto "Meta": usar la IA para construir una herramienta que usa IA para mejorar el desarrollo de software.

## 2. Metodolog铆a de Desarrollo: "AI-Driven Development"
Para la concepci贸n y documentaci贸n de este proyecto, se ha utilizado una metodolog铆a h铆brida humano-IA, actuando la IA (Modelos LLM avanzados) como **Arquitecto Consultor**.

### Herramientas utilizadas:
* **Copilot & LLMs:** Utilizados no solo para autocompletar c贸digo, sino para:
    * Generar estructuras de documentaci贸n (como este archivo).
    * Simular roles (Business Analyst, DevOps Engineer) para validar ideas.
    * Sintetizar grandes vol煤menes de documentaci贸n t茅cnica.
* **RAG (Retrieval-Augmented Generation):** La propia t茅cnica que implementa el proyecto se ha usado para estructurarlo, alimentando al asistente con los temarios del m谩ster para asegurar coherencia acad茅mica.

## 3. Aplicaci贸n del M贸dulo de Infraestructura y Cloud
El m贸dulo de Infraestructura es la columna vertebral que hace viable este proyecto. No se trata solo de "subir c贸digo", sino de dise帽ar un sistema desplegable y mantenible.

### C贸mo se aplica el M贸dulo 7 al Workflow de SoftArchitect:
1.  **Dockerizaci贸n desde el D铆a 0:** * Para garantizar que el m贸dulo de IA (Python/RAG) y el Frontend (Flutter) funcionen igual en cualquier m谩quina, se define todo en `docker-compose.yaml`.
    * *Justificaci贸n del M谩ster:* Contenerizaci贸n para evitar el "works on my machine".
    
2.  **Infraestructura como C贸digo (IaC):**
    * La definici贸n de los servicios vectoriales y la API se gestiona mediante scripts declarativos, permitiendo recrear el entorno en segundos.

3.  **Estrategia de Despliegue (CI/CD):**
    * Se dise帽an pipelines (GitHub Actions) que no solo corren tests, sino que verifican la integridad de la base de conocimiento RAG.
    * *Concepto aplicado:* Automatizaci贸n del ciclo de vida y Quality Gates.

4.  **Observabilidad:**
    * Integraci贸n futura de herramientas de monitoreo para ver la latencia de las respuestas de la IA (concepto clave en LLMOps visto en el m贸dulo).

5.  **Automatizaci贸n de Documentaci贸n (Docs-as-Code):**
    * Se ha implementado un pipeline de **Integraci贸n Continua de Conocimiento**.
    * La documentaci贸n reside junto al c贸digo (Markdown en Git), pero se despliega autom谩ticamente a Notion mediante **n8n** y Webhooks.
    * *Justificaci贸n:* Elimina la desincronizaci贸n entre lo que hace el c贸digo y lo que dice la documentaci贸n, aplicando principios DevOps a la gesti贸n del conocimiento.

---

#  Memoria Metodol贸gica: Ingenier铆a y Decisiones Arquitect贸nicas

## 1. Introducci贸n
Este documento justifica las decisiones t茅cnicas tomadas para el desarrollo de **SoftArchitect AI**, vincul谩ndolas directamente con los conocimientos adquiridos en el M谩ster de Desarrollo con IA. El objetivo no es solo construir una herramienta 煤til, sino demostrar la capacidad de dise帽ar sistemas complejos, escalables y desplegables.

## 2. Aplicaci贸n del M贸dulo de Arquitectura de Software
Se ha optado por una arquitectura de **Microservicios Locales**.

* **Decisi贸n:** Separar el Frontend (Flutter) del Backend de IA (Python).
* **Justificaci贸n (Clean Architecture):** Esta separaci贸n de responsabilidades permite que la UI evolucione independientemente del motor de inteligencia artificial. Si ma帽ana queremos cambiar Ollama por OpenAI API, solo tocamos el servicio de Python; el Frontend en Flutter ni se entera.
* **Patr贸n Ports & Adapters:** El servicio Python act煤a como un adaptador que "habla" con el LLM y la Base Vectorial, exponiendo una API REST limpia al dominio (el usuario en Flutter).

## 3. Aplicaci贸n del M贸dulo de Infraestructura y Cloud
El mayor reto t茅cnico de este proyecto es la **Portabilidad**. Al usar modelos de IA locales, la configuraci贸n del entorno suele ser una pesadilla ("instala Python, instala drivers de CUDA, instala Ollama...").

**Soluci贸n Implementada: Docker Compose "Self-Contained"**
Hemos aplicado los principios de Contenerizaci贸n para crear un entorno reproducible 100%.

* **Orquestaci贸n:** Un 煤nico archivo `docker-compose.yaml` levanta 3 contenedores coordinados:
    1.  `softarchitect-backend`: La API en FastAPI.
    2.  `softarchitect-vector-db`: ChromaDB persistente.
    3.  `ollama-service`: El motor de inferencia.
    
* **Automatizaci贸n (IaC):** Se ha dise帽ado un *entrypoint script* personalizado para el contenedor de Ollama. Este script verifica al inicio si el modelo LLM necesario (ej: `llama3`) est谩 descargado. Si no, lo descarga autom谩ticamente ( `ollama pull`) antes de declarar el servicio como "Healthy". Esto garantiza la experiencia de "Clonar y Ejecutar" sin pasos manuales.

## 4. Aplicaci贸n del M贸dulo de Calidad y Testing
* **Frontend:** Tests de Widgets en Flutter para asegurar que los formularios de requisitos y la visualizaci贸n de respuestas son robustos.
* **Backend:** Tests unitarios en Python (Pytest) para validar la l贸gica de construcci贸n de prompts y la conexi贸n con ChromaDB.
* **RAG Evaluation:** (Fase futura) Implementaci贸n de "RAGAS" para medir la precisi贸n y fidelidad de las respuestas generadas por el sistema frente a la documentaci贸n base.

## 5. Aplicaci贸n del M贸dulo de Seguridad
* **Privacidad por Dise帽o (Privacy by Design):** Al elegir un stack local (Ollama + ChromaDB), garantizamos que el c贸digo o las ideas de proyecto del usuario **nunca salen de su m谩quina**. Esto es cr铆tico para una herramienta que maneja propiedad intelectual.
* **Sanitizaci贸n:** La API de Python implementa validaciones estrictas (Pydantic) para evitar inyecciones de prompts maliciosos.

---

## 6. Estrategia de Desarrollo Remoto (HomeLab & Tailscale)
Para maximizar la eficiencia y simular un entorno de producci贸n real desde el primer d铆a, se ha optado por una arquitectura de **Desarrollo Remoto (Remote Development)**.

### 6.1. Arquitectura F铆sica vs. L贸gica
* **HomeLab (The Powerhouse):** Un servidor Ubuntu Server con Docker Engine. Aloja el c贸digo fuente, la base de datos vectorial (ChromaDB), el motor de IA (Ollama) y ejecuta los procesos de compilaci贸n.
* **Port谩til (Thin Client):** Act煤a meramente como interfaz de usuario. No almacena c贸digo ni ejecuta cargas de trabajo pesadas.
* **Conectividad:** Se utiliza **VS Code Remote - SSH** para conectar el IDE local directamente al sistema de archivos del servidor.

### 6.2. Ventajas del Stack
1.  **Entorno Inmutable:** Al estar todo dockerizado en el servidor, no importa si cambio de port谩til o formateo; el entorno de desarrollo sigue intacto.
2.  **Potencia de IA:** Los modelos LLM (Llama 3) corren en el hardware del servidor (CPU/GPU dedicados), liberando los recursos del port谩til para navegaci贸n y ofim谩tica.
3.  **Ubicuidad (Tailscale):** Se integra una red Mesh VPN (Tailscale) que permite acceder al entorno de desarrollo desde cualquier lugar del mundo de forma segura, sin abrir puertos en el router.

### 6.3. Workflow de Pruebas
* **Fase de Desarrollo:** Se utiliza `flutter run -d web-server` en el servidor. VS Code realiza un *Port Forwarding* autom谩tico a trav茅s del t煤nel SSH, permitiendo ver y depurar la aplicaci贸n en el navegador del port谩til local (`localhost:8080`) como si se ejecutara nativamente.
* **Fase de Release:** Para compilaciones nativas m贸viles, se utiliza *Wireless Debugging* o un pipeline de CI/CD que genera los binarios (APK/EXE) listos para descarga.

---

## 7. Validaci贸n Temprana: Simulaci贸n "Mago de Oz"
Antes de escribir el c贸digo fuente, se ejecut贸 una fase de **Prototipado de Prompt (Prompt Engineering)** simulando el comportamiento del sistema final.
* **Objetivo:** Validar si el *Master Workflow* es capaz de generar entregables 煤tiles (Vision Statements, ADRs, Dockerfiles) sin intervenci贸n humana creativa.
* **Resultado:** La simulaci贸n confirm贸 que, con el contexto adecuado, el sistema puede actuar como un "Arquitecto Senior", reduciendo la incertidumbre del proyecto antes de la fase de desarrollo.

## 8. Evoluci贸n del RAG: Arquitectura de Contexto Estructurado
Se ha pivotado de un enfoque RAG tradicional (b煤squeda sem谩ntica en documentos desestructurados) a una **Arquitectura de Contexto Estructurado**.

### 8.1. Ingenier铆a Inversa de Casos de xito
Se analiz贸 el proyecto real *GuauGuauCars* (desarrollado por el autor) para extraer los patrones de 茅xito que facilitaron el desarrollo con Copilot. Se identificaron cuatro pilares de contexto necesarios:
1.  **Identidad T茅cnica:** Definici贸n de roles (ej: `AGENTS.md`).
2.  **Reglas de Oro:** Restricciones t茅cnicas expl铆citas (ej: `TESTING_RULES.md`).
3.  **Mapa Estructural:** Definici贸n de la arquitectura de carpetas.
4.  **Flujos de Trabajo:** Procedimientos estandarizados (GitFlow, TDD).

### 8.2. El concepto de "Meta-Plantillas"
Para replicar este 茅xito en cualquier tecnolog铆a, SoftArchitect AI utilizar谩 **Meta-Plantillas** (como `UNIVERSAL_AGENTS.md`) que se rellenan din谩micamente seg煤n el stack del usuario (Tech Packs), garantizando que el asistente de IA siempre tenga un contexto de alta calidad ("Garbage In, Garbage Out" mitigado).

---

## 9. Pivote T茅cnico: Adaptabilidad de Hardware
Durante la fase de validaci贸n t茅cnica ("The Fire Test"), se identific贸 un cuello de botella cr铆tico en servidores dom茅sticos antiguos (ausencia de instrucciones AVX en CPUs pre-2011), haciendo inviable la ejecuci贸n local de modelos, incluso los m谩s ligeros ("TinyLlama").

### Decisi贸n de Dise帽o:
En lugar de restringir el software a hardware de gama alta, se opt贸 por una **Arquitectura H铆brida**. Se integra **Groq Cloud** como fallback transparente. Esto permite desarrollar y testear la l贸gica del RAG en el HomeLab (usando nube r谩pida) y desplegar en producci贸n local o en el port谩til potente (usando Ollama) con el mismo codebase. Es un ejemplo pr谩ctico de c贸mo la infraestructura dicta decisiones de arquitectura de software.
