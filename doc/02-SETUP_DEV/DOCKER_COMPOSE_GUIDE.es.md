# üêã Docker Compose Setup Guide - SoftArchitect AI

> **Last Updated:** 28 de enero de 2026  
> **Status:** ‚úÖ Production Ready  
> **Tested On:** Linux (Ubuntu 22.04), Windows (WSL2), macOS (M1/Intel)

---

## üìã Tabla de Contenidos

1. [Requisitos Previos](#requisitos-previos)
2. [Instalaci√≥n R√°pida](#instalaci√≥n-r√°pida)
3. [Modos de Ejecuci√≥n](#modos-de-ejecuci√≥n)
4. [Verificaci√≥n de Servicios](#verificaci√≥n-de-servicios)
5. [Troubleshooting](#troubleshooting)
6. [Performance Tuning](#performance-tuning)
7. [Arquitectura Detallada](#arquitectura-detallada)

---

## ‚úÖ Requisitos Previos

### Hardware M√≠nimo

```yaml
CPU: 2 cores (4 cores recomendado)
RAM: 8GB (4GB Ollama + 2GB ChromaDB + 2GB Sistema)
Disco: 20GB libres (10GB Ollama + 5GB Docker overhead + 5GB cach√©)
GPU: Opcional (NVIDIA CUDA 11.8+ para acelerar Ollama)
```

### Software Requerido

```bash
# Docker Desktop o Docker Engine + Docker Compose
docker --version
# Expected: Docker version 24.0.0 or higher

docker compose version
# Expected: Docker Compose version 2.20.0 or higher
```

**Instalaci√≥n:**

- **Linux:** `curl -fsSL https://get.docker.com | sh`
- **macOS/Windows:** [Docker Desktop](https://www.docker.com/products/docker-desktop/)

### GPU NVIDIA (Opcional pero Recomendado)

Si tienes GPU NVIDIA, descomenta en `docker-compose.yml`:

```yaml
# En servicio ollama:
deploy:
  resources:
    reservations:
      devices:
        - driver: nvidia
          count: 1
          capabilities: [gpu]
```

**Instalaci√≥n NVIDIA Container Toolkit:**

```bash
# Linux
distribution=$(. /etc/os-release;echo $ID$VERSION_ID)
curl -fsSL https://nvidia.github.io/nvidia-docker/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-docker-keyring.gpg
sudo apt-get install -y nvidia-docker2 && sudo systemctl restart docker

# Verify
docker run --rm --gpus all nvidia/cuda:12.0.0-runtime-ubuntu22.04 nvidia-smi
```

---

## üöÄ Instalaci√≥n R√°pida

### Paso 1: Clonar Repositorio

```bash
git clone https://github.com/Pitcher755/soft-architect-ai.git
cd soft-architect-ai
```

### Paso 2: Crear Archivos de Configuraci√≥n

```bash
# En infrastructure/
cd infrastructure
cp .env.example .env

# En src/server/
cd ../src/server
cp .env.example .env
```

Editar ambos `.env` seg√∫n tu preferencia (defaults funcionan para desarrollo local).

### Paso 3: Iniciar Servicios

```bash
cd infrastructure
docker compose up --build
```

**Esperado:**
- Ollama descargar√° modelo (2-5 minutos, ~5GB)
- ChromaDB se iniciar√° (~10s)
- FastAPI estar√° listo (~5s)

### Paso 4: Verificar

```bash
# En otra terminal
curl http://localhost:8000/api/v1/health
# Expected: {"status":"OK","message":"SoftArchitect AI backend is running","version":"0.1.0"}

# Swagger UI
open http://localhost:8000/docs
# Expected: Interactive API documentation
```

---

## üéõÔ∏è Modos de Ejecuci√≥n

### Modo 1: Desarrollo (Hot-Reload)

```bash
cd infrastructure
docker compose up
```

**Caracter√≠sticas:**
- ‚úÖ Hot-reload de c√≥digo Python (cambios se reflejan al guardar)
- ‚úÖ Logs en vivo en terminal
- ‚úÖ Debug mode activado
- ‚ùå No recomendado para producci√≥n

### Modo 2: Desarrollo en Background

```bash
docker compose up -d

# Ver logs
docker compose logs -f api-server

# Ver logs solo de Ollama
docker compose logs -f ollama
```

### Modo 3: Producci√≥n (Detached)

```bash
# 1. Editar .env: DEBUG=False, IRON_MODE=True
# 2. Iniciar en background
docker compose up -d

# 3. Verificar estado
docker compose ps

# 4. Ver logs en caso de problemas
docker compose logs

# 5. Detener servicios
docker compose down
```

### Modo 4: Rebuild Completo (Limpiar Cache)

```bash
# Detener y remover contenedores + vol√∫menes
docker compose down -v

# Eliminar im√°genes (para actualizar)
docker rmi sa_api

# Reconstruir
docker compose up --build
```

---

## üîç Verificaci√≥n de Servicios

### Verificar Estado

```bash
# Ver estado de todos los servicios
docker compose ps

# Salida esperada:
# NAME           IMAGE                    STATUS
# sa_ollama      ollama/ollama:latest     Up (healthy)
# sa_chromadb    chromadb/chroma:latest   Up (healthy)
# sa_api         sa_api:latest            Up (healthy)
```

### Logs por Servicio

```bash
# API (la m√°s importante)
docker compose logs api-server --tail 50

# Ollama (ver descargas de modelo)
docker compose logs ollama --tail 50

# ChromaDB
docker compose logs chromadb --tail 50

# Todos
docker compose logs --tail 100
```

### Health Checks

```bash
# API
curl -s http://localhost:8000/api/v1/health | jq .

# Ollama
curl -s http://localhost:11434/api/status | jq .

# ChromaDB (requiere expose del puerto)
curl -s http://localhost:8000 | jq .
```

### Acceso a Contenedores

```bash
# Entrar en shell del API
docker compose exec api-server bash

# Ver variables de ambiente
docker compose exec api-server env | grep -i llm

# Ver SQLite en vivo
docker compose exec api-server sqlite3 /app/data/softarchitect.db ".tables"

# Entrar en Ollama
docker compose exec ollama bash
# Ver modelos descargados: ollama list
```

---

## üêõ Troubleshooting

### Problema 1: "Cannot connect to Docker daemon"

```bash
# Soluci√≥n:
sudo systemctl start docker  # Linux
# o abrir Docker Desktop (macOS/Windows)

# Verify
docker ps
```

### Problema 2: "Port 8000 already in use"

```bash
# Encontrar qu√© est√° usando puerto 8000
lsof -i :8000  # macOS/Linux
netstat -ano | findstr :8000  # Windows

# Opci√≥n A: Cambiar puerto en docker-compose.yml
ports:
  - "8001:8000"  # Ahora ser√° http://localhost:8001

# Opci√≥n B: Matar proceso existente
kill -9 <PID>
```

### Problema 3: "Ollama out of memory"

```bash
# S√≠ntoma: Ollama crashea al procesar requests

# Soluci√≥n 1: Aumentar mem_limit
# En docker-compose.yml, secci√≥n deploy de ollama:
memory: 4GB  # o m√°s

# Soluci√≥n 2: Usar modelo m√°s peque√±o
OLLAMA_MODEL=qwen2.5-coder:1.5b  # vs 7b

# Soluci√≥n 3: Verificar que tengas espacio en disco
docker system df
```

### Problema 4: "ChromaDB connection refused"

```bash
# S√≠ntoma: API no conecta a ChromaDB

# Soluci√≥n 1: Verificar que ChromaDB est√© listo
docker compose logs chromadb

# Soluci√≥n 2: Reiniciar ChromaDB
docker compose restart chromadb

# Soluci√≥n 3: Revisar variables de ambiente
docker compose exec api-server env | grep -i chroma
# CHROMA_HOST debe ser "chromadb", CHROMA_PORT "8000"
```

### Problema 5: "Connection refused to Ollama"

```bash
# S√≠ntoma: API falla con "Cannot connect to Ollama:11434"

# Verificar Ollama est√° corriendo
docker compose exec api-server curl http://ollama:11434/api/status

# Si falla, revisar logs
docker compose logs ollama

# Reiniciar
docker compose restart ollama
```

### Problema 6: "ModuleNotFoundError: No module named 'app'"

```bash
# S√≠ntoma: API crashea en startup

# Causa: El COPY en Dockerfile no funciona bien

# Soluci√≥n:
# 1. Verificar que requirements.txt existe en src/server/
# 2. Rebuild:
docker compose up --build

# 3. Verificar dentro del contenedor:
docker compose exec api-server ls -la /app/app/main.py
```

### Problema 7: "NVIDIA Container runtime not found"

```bash
# Si descomentas la secci√≥n GPU pero no tienes driver instalado

# Opci√≥n A: Instalar NVIDIA Container Toolkit (recomendado)
# https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/

# Opci√≥n B: Comentar GPU config (volver a CPU-only)
# En docker-compose.yml, comentar:
# devices:
#   - driver: nvidia
```

---

## ‚ö° Performance Tuning

### RAM Eficiente (para m√°quinas limitadas)

```yaml
# docker-compose.yml
services:
  ollama:
    deploy:
      resources:
        limits:
          memory: 1.5GB  # Redacir de 2GB
  chromadb:
    deploy:
      resources:
        limits:
          memory: 256MB  # OK para mayoria
  api-server:
    deploy:
      resources:
        limits:
          memory: 256MB  # Reducir de 512MB

# .env
OLLAMA_MODEL=qwen2.5-coder:1.5b  # Modelo m√°s peque√±o
```

### M√°xima Velocidad (m√°quinas potentes + GPU)

```yaml
# docker-compose.yml
services:
  ollama:
    deploy:
      resources:
        limits:
          memory: 4GB
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
  api-server:
    deploy:
      resources:
        limits:
          memory: 1GB

# .env
OLLAMA_MODEL=mistral:7b  # Mejor balance velocidad/quality
LLM_PROVIDER=cloud  # Considerar Groq si necesitas <1s
```

### Diagn√≥stico de Recursos

```bash
# Ver uso real de Docker
docker stats

# Output:
# CONTAINER       CPU %    MEM USAGE / LIMIT
# sa_ollama       45.2%    1.8GB / 2GB
# sa_chromadb     0.2%     45MB / 512MB
# sa_api          0.1%     120MB / 512MB
```

---

## üèóÔ∏è Arquitectura Detallada

### Flujo de Datos

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Flutter App    ‚îÇ
‚îÇ  (localhost)    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ HTTP
         ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   FastAPI Backend       ‚îÇ
‚îÇ   (Port 8000)           ‚îÇ
‚îÇ   - API Routes          ‚îÇ
‚îÇ   - RAG Orchestration   ‚îÇ
‚îÇ   - Auth                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ         ‚îÇ
         ‚îÇ Network ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îê
    ‚îÇ   sa_network    ‚îÇ
    ‚îÇ  (172.25.0.0/16)‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îò
         ‚îÇ         ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ Ollama ‚îÇ  ‚îÇChromaDB‚îÇ
    ‚îÇ :11434 ‚îÇ  ‚îÇ :8000  ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ         ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ  Docker Volumes    ‚îÇ
    ‚îÇ - ollama_storage   ‚îÇ
    ‚îÇ - chroma_storage   ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Stack de Puertos

| Servicio   | Puerto | Acceso        | Prop√≥sito |
|-----------|--------|---------------|-----------|
| API       | 8000   | Host + Network | REST API + Swagger |
| Ollama    | 11434  | Network only  | LLM inference |
| ChromaDB  | 8000   | Network only  | Vector DB API |

### Vol√∫menes

| Volumen | Ubicaci√≥n | Tama√±o | Contenido |
|---------|-----------|--------|-----------|
| ollama_storage | `/root/.ollama` | ~5-10GB | Modelos descargados |
| chroma_storage | `/chroma/chroma` | ~100-500MB | Embeddings indexados |
| logs | `./logs` | Variable | Logs de aplicaci√≥n |
| data | `./data` | ~200MB | SQLite DB + cach√© |

---

## üìö Referencias

- **AGENTS.md:** Definici√≥n de arquitectura del proyecto
- **context/30-ARCHITECTURE/TECH_STACK_DETAILS.es.md:** Stack tecnol√≥gico
- **src/server/README.md:** Documentaci√≥n de backend
- **Docker Compose Docs:** https://docs.docker.com/compose/
- **Ollama Docs:** https://ollama.ai
- **ChromaDB Docs:** https://docs.trychroma.com

---

## ü§ù Soporte

Si encuentras problemas:

1. **Revisa los logs:** `docker compose logs` 
2. **Consulta Troubleshooting arriba**
3. **Abre issue en GitHub:** https://github.com/Pitcher755/soft-architect-ai/issues
4. **Contacta al equipo:** team@softarchitect.ai

---

**Happy Coding! üöÄ**
