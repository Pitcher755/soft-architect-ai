services:
  # ================================
  # FastAPI Backend Service
  # ================================
  api-server:
    build:
      context: ../src/server
      dockerfile: Dockerfile
    container_name: sa_api
    ports:
      - "${BACKEND_PORT:-8000}:8000"
    environment:
      - ENVIRONMENT=${ENVIRONMENT:-development}
      - DEBUG=${DEBUG:-true}
      - OLLAMA_BASE_URL=http://ollama:11434
      - CHROMADB_HOST=chromadb
      - CHROMADB_PORT=8000
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
    volumes:
      - ./data/logs:/app/logs
    depends_on:
      chromadb:
        condition: service_healthy
      ollama:
        condition: service_healthy
    networks:
      - sa_network
    restart: unless-stopped
    healthcheck:
      test: [ "CMD-SHELL", "python -c \"import socket; socket.create_connection(('localhost', 8000), timeout=2)\"" ]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 10s

  # ================================
  # ChromaDB Vector Database Service
  # ================================
  chromadb:
    image: ghcr.io/chroma-core/chroma:latest
    container_name: sa_chromadb
    ports:
      - "8001:8000"
    environment:
      - CHROMA_DB_IMPL=duckdb
      - PERSIST_DIRECTORY=/data
    volumes:
      - chromadb_data:/data
    networks:
      - sa_network
    restart: unless-stopped
    healthcheck:
      test: [ "CMD-SHELL", "bash -c 'echo > /dev/tcp/localhost/8000'" ]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 10s

  # ================================
  # Ollama LLM Engine Service
  # ================================
  ollama:
    image: ollama/ollama:latest
    container_name: sa_ollama
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    environment:
      - OLLAMA_HOST=0.0.0.0:11434
      - OLLAMA_MODELS=/root/.ollama/models
    networks:
      - sa_network
    restart: unless-stopped
    deploy:
      resources:
        reservations:
          # GPU support: Active for Nvidia RTX 3050
          # For systems without GPU: comment the following 4 lines and uncomment 'devices: []'
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
          # devices: []  # Uncomment if you do NOT have Nvidia GPU
    healthcheck:
      test: [ "CMD-SHELL", "bash -c 'echo > /dev/tcp/localhost/11434'" ]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 30s

# ================================
# Docker Networks Configuration
# ================================
networks:
  sa_network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.25.0.0/16

# ================================
# Volumes (Data Persistence)
# ================================
volumes:
  chromadb_data:
    driver: local
  ollama_data:
    driver: local
