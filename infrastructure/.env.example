# ═══════════════════════════════════════════════════════════════
# Docker Compose Environment Configuration
#
# Used by docker-compose.yml for:
#   - Container image versions
#   - Resource limits (RAM, CPU)
#   - Service configuration
#
# INSTRUCTIONS:
# 1. This file is automatically loaded by docker-compose
# 2. Edit values according to your environment
# 3. Is in .gitignore (never committed)
# ═══════════════════════════════════════════════════════════════

# ─────────────────────────────────────────────────────────────
# DOCKER IMAGES (versions)
# ─────────────────────────────────────────────────────────────
OLLAMA_IMAGE_VERSION=latest
CHROMADB_IMAGE_VERSION=latest
PYTHON_VERSION=3.12.3

# ─────────────────────────────────────────────────────────────
# RESOURCE LIMITS
# ─────────────────────────────────────────────────────────────
# Ollama: The most resource-hungry (large models)
# Typical: 2GB for qwen2.5-coder:7b, 4GB for larger models
OLLAMA_MEMORY_LIMIT=2GB
OLLAMA_CPU_SHARES=1024

# ChromaDB: Lightweight, 512MB is sufficient
CHROMADB_MEMORY_LIMIT=512MB

# FastAPI: Small, 512MB is generous
API_MEMORY_LIMIT=512MB

# ─────────────────────────────────────────────────────────────
# LLM PROVIDER (local or cloud)
# ─────────────────────────────────────────────────────────────
LLM_PROVIDER=local
# LLM_PROVIDER=cloud  # Uncomment to use Groq

# ─────────────────────────────────────────────────────────────
# OLLAMA SETTINGS (Local LLM)
# ─────────────────────────────────────────────────────────────
OLLAMA_MODEL=qwen2.5-coder:7b
# Alternatives:
# OLLAMA_MODEL=llama2:7b          # General purpose
# OLLAMA_MODEL=mistral:7b         # Balance speed/quality
# OLLAMA_MODEL=neural-chat:7b     # Chat optimized
# OLLAMA_MODEL=openhermes:7b      # Very good for code

# ─────────────────────────────────────────────────────────────
# GROQ SETTINGS (Cloud LLM - If LLM_PROVIDER=cloud)
# ─────────────────────────────────────────────────────────────
GROQ_API_KEY=your-groq-api-key-here
GROQ_MODEL=llama2-70b-4096

# ─────────────────────────────────────────────────────────────
# PRIVACY & SECURITY
# ─────────────────────────────────────────────────────────────
DEBUG=False
IRON_MODE=True  # Paranoid mode: prevents external calls
PII_DETECTION_ENABLED=True
